{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1419d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk\n",
    "#nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d64461",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "AI_sent= sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem',\n",
       " '-',\n",
       " 'solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest',\n",
       " '-',\n",
       " 'growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e10116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "snt = sent_tokenize(AI)\n",
    "snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffcd301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0c5fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First',\n",
       " 'class',\n",
       " 'of',\n",
       " 'AI',\n",
       " ',',\n",
       " 'We',\n",
       " 'need',\n",
       " 'to',\n",
       " 'spend',\n",
       " 'more',\n",
       " 'than',\n",
       " '4',\n",
       " 'hrs',\n",
       " 'for',\n",
       " 'practice',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams\n",
    "\n",
    "string  = 'First class of AI,We need to spend more than 4 hrs for practice.'\n",
    "# To know how many words in the string use word_tokenize(), this func considers symbols,exclametories as a word\n",
    "wrd_tkn = nltk.word_tokenize(string)\n",
    "wrd_tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f5e7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrd_tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4147a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('First', 'class'),\n",
       " ('class', 'of'),\n",
       " ('of', 'AI'),\n",
       " ('AI', ','),\n",
       " (',', 'We'),\n",
       " ('We', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'spend'),\n",
       " ('spend', 'more'),\n",
       " ('more', 'than'),\n",
       " ('than', '4'),\n",
       " ('4', 'hrs'),\n",
       " ('hrs', 'for'),\n",
       " ('for', 'practice'),\n",
       " ('practice', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To devide 2 words to gether use bigrams(arg) func\n",
    "bgrm = list(nltk.bigrams(wrd_tkn))\n",
    "bgrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78885e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('First', 'class', 'of'),\n",
       " ('class', 'of', 'AI'),\n",
       " ('of', 'AI', ','),\n",
       " ('AI', ',', 'We'),\n",
       " (',', 'We', 'need'),\n",
       " ('We', 'need', 'to'),\n",
       " ('need', 'to', 'spend'),\n",
       " ('to', 'spend', 'more'),\n",
       " ('spend', 'more', 'than'),\n",
       " ('more', 'than', '4'),\n",
       " ('than', '4', 'hrs'),\n",
       " ('4', 'hrs', 'for'),\n",
       " ('hrs', 'for', 'practice'),\n",
       " ('for', 'practice', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to disply 3 words together use trigrams(arg) func\n",
    "trgm = list(nltk.trigrams(wrd_tkn))\n",
    "trgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48e48f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First',\n",
       " 'class',\n",
       " 'of',\n",
       " 'AI',\n",
       " ',',\n",
       " 'We',\n",
       " 'need',\n",
       " 'to',\n",
       " 'spend',\n",
       " 'more',\n",
       " 'than',\n",
       " '4',\n",
       " 'hrs',\n",
       " 'for',\n",
       " 'practice',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd_tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab565d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First class of AI,We need to spend more than 4 hrs for practice.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65e9f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('First', 'class', 'of', 'AI', ','),\n",
       " ('class', 'of', 'AI', ',', 'We'),\n",
       " ('of', 'AI', ',', 'We', 'need'),\n",
       " ('AI', ',', 'We', 'need', 'to'),\n",
       " (',', 'We', 'need', 'to', 'spend'),\n",
       " ('We', 'need', 'to', 'spend', 'more'),\n",
       " ('need', 'to', 'spend', 'more', 'than'),\n",
       " ('to', 'spend', 'more', 'than', '4'),\n",
       " ('spend', 'more', 'than', '4', 'hrs'),\n",
       " ('more', 'than', '4', 'hrs', 'for'),\n",
       " ('than', '4', 'hrs', 'for', 'practice'),\n",
       " ('4', 'hrs', 'for', 'practice', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to display n words use ngrams(arg,count of numbers to print in 1 list)\n",
    "ngrm = list(nltk.ngrams(wrd_tkn,5))\n",
    "ngrm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4dd29",
   "metadata": {},
   "source": [
    " PorterStemmer is a stemming algorithm in NLTK (Natural Language Toolkit).\n",
    " It reduces words to their root/stem form by chopping off common endings \n",
    " like -ing, -ed, -s, -ly, etc.\n",
    "\n",
    " What is Stemming?\n",
    "\n",
    " Stemming is the process of removing suffixes/prefixes to get the root word.\n",
    "\n",
    " Example:\n",
    "\n",
    " \"running\" â†’ \"run\"\n",
    "\n",
    " \"flies\" â†’ \"fli\"\n",
    "\n",
    " \"happiness\" â†’ \"happi\"\n",
    "\n",
    "The stem may not always be a valid English word (unlike lemmatization, which produces valid dictionary forms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846e01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  find\n",
      "leaving :  leav\n",
      "action :  action\n",
      "brushing :  brush\n",
      "jumping :  jump\n",
      "acting :  act\n",
      "singing :  sing\n",
      "beautifully :  beauti\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "prtrstm =PorterStemmer()\n",
    "words = ['Finding','leaving','action','brushing','jumping','acting','singing','beautifully']\n",
    "\n",
    "for i in words:\n",
    "    print(i,': ',prtrstm.stem(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31712d98",
   "metadata": {},
   "source": [
    "What is Lancaster Stemmer?\n",
    "\n",
    "Itâ€™s a rule-based stemming algorithm that applies an iterative set of rules to reduce words to their root.\n",
    "\n",
    "Unlike PorterStemmer, it is more aggressive â†’ it cuts words down more heavily, sometimes too much.\n",
    "\n",
    "Because of this, it often produces very short stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a403299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  find\n",
      "leaving :  leav\n",
      "action :  act\n",
      "brushing :  brush\n",
      "jumping :  jump\n",
      "acting :  act\n",
      "singing :  sing\n",
      "beautifully :  beauty\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lncstm = LancasterStemmer()\n",
    "for i in words:\n",
    "    print(i,\": \",lncstm.stem(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa561b49",
   "metadata": {},
   "source": [
    "What is Snowball Stemmer?\n",
    "\n",
    "Developed by Martin Porter (the same person who created PorterStemmer).\n",
    "\n",
    "Itâ€™s part of the Snowball framework (a language for writing stemming algorithms).\n",
    "\n",
    "Supports multiple languages (English, French, German, Spanish, etc.), unlike Porter or Lancaster, which mostly focus on English.\n",
    "\n",
    "Less aggressive than Lancaster, but often produces cleaner stems than Porter.\n",
    "\n",
    "The Snowball Stemmer (also called the Porter2 stemmer) is an improved version of the original Porter stemmer.\n",
    "Itâ€™s available in NLTK and is widely used in NLP because it balances accuracy and aggressiveness better than Lancaster or Porter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e79d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  find\n",
      "leaving :  leav\n",
      "action :  action\n",
      "brushing :  brush\n",
      "jumping :  jump\n",
      "acting :  act\n",
      "singing :  sing\n",
      "beautifully :  beauti\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snbstm = SnowballStemmer('english')\n",
    "for i in words:\n",
    "    print(i,\": \",snbstm.stem(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de56af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sukaran :  sukaran\n",
      "marahaban :  marahaban\n",
      "madrasa :  madrasa\n"
     ]
    }
   ],
   "source": [
    "wrd = ['sukaran','marahaban','madrasa']\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snbstm = SnowballStemmer('arabic')\n",
    "for i in wrd:\n",
    "    print(i,\": \",snbstm.stem(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2687d",
   "metadata": {},
   "source": [
    "The WordNet Lemmatizer is a lemmatization tool in NLTK that uses the WordNet lexical database to reduce words to their base or dictionary form (called a lemma).\n",
    "\n",
    "ðŸ”¹ Difference: Stemming vs Lemmatization\n",
    "\n",
    "Stemming (Porter, Lancaster, Snowball): just chops off endings â†’ results may not be real words (happiness â†’ happi).\n",
    "\n",
    "Lemmatization (WordNet Lemmatizer): uses vocabulary + grammar rules â†’ always returns a valid dictionary word (happiness â†’ happy).\n",
    "\n",
    "ðŸ”¹ How WordNet Lemmatizer Works\n",
    "\n",
    "It looks up words in the WordNet database (a large lexical database of English).\n",
    "\n",
    "Considers part-of-speech (POS) to give accurate lemmas. we have to mension pos = (a = adjective of the word, v = verb,n = noun of the word etc)as a parameter of the lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d15a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f88248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finding',\n",
       " 'leaving',\n",
       " 'action',\n",
       " 'brushing',\n",
       " 'jumping',\n",
       " 'acting',\n",
       " 'singing',\n",
       " 'beautifully']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee325cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  Finding\n",
      "leaving :  leave\n",
      "action :  action\n",
      "brushing :  brush\n",
      "jumping :  jump\n",
      "acting :  act\n",
      "singing :  sing\n",
      "beautifully :  beautifully\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i,\": \",word_lem.lemmatize(i,pos= 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64fef10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  Finding\n",
      "leaving :  leaving\n",
      "action :  action\n",
      "brushing :  brushing\n",
      "jumping :  jumping\n",
      "acting :  acting\n",
      "singing :  singing\n",
      "beautifully :  beautifully\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i,\": \",word_lem.lemmatize(i,pos= 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "051b8fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding :  Finding\n",
      "leaving :  leaving\n",
      "action :  action\n",
      "brushing :  brushing\n",
      "jumping :  jumping\n",
      "acting :  acting\n",
      "singing :  singing\n",
      "beautifully :  beautifully\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i,\": \",word_lem.lemmatize(i,pos= 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440f6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa3123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
